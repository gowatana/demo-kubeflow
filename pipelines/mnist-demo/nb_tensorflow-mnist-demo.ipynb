{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/gist/gowatana/1fc66e48db015732e3a88870af2ac67b/demo-tensorflow-mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLEkkAZNgQih"
   },
   "source": [
    "参考：初心者のための TensorFlow 2.0 入門\n",
    "* https://www.tensorflow.org/tutorials/quickstart/beginner?hl=ja\n",
    "\n",
    "パイプラインのデモむけに、あえて4分割してある。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjBez0LYtIBT"
   },
   "source": [
    "# 1. モデルの作成（コード分割）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZT5V_7XBtCIa"
   },
   "source": [
    "TensorFlowのバージョン確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_r9_EO26s8Zh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.3\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 画像判別モデルの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBmLDehltRLq"
   },
   "source": [
    "## 1-1. データセットの保存\n",
    "\n",
    "サンプル データセット（MNIST）をダウンロードして保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. データセットの保存\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# データセットをダウンロードして保存するディレクトリを指定\n",
    "save_dir = './dataset'\n",
    "\n",
    "# ディレクトリが存在しない場合にディレクトリを作成\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "# MNISTデータセットをダウンロード（初回のみ）\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# データセットを指定したディレクトリに保存\n",
    "np.savez_compressed(os.path.join(save_dir, 'mnist.npz'), x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. データセットをロードして前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. データセットをロードして前処理\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# データセットをダウンロードして保存するディレクトリを指定\n",
    "load_dir = './dataset'\n",
    "save_dir = './preproc_dataset'\n",
    "\n",
    "# ディレクトリが存在しない場合にディレクトリを作成\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "with np.load(os.path.join(load_dir, 'mnist.npz'), allow_pickle=True) as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "np.savez_compressed(os.path.join(save_dir, 'mnist_normalized.npz'), x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. 前処理済みのデータセットで学習 → モデルを保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 09:00:21.578795: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 22s 11ms/step - loss: 0.2950 - accuracy: 0.9141\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1426 - accuracy: 0.9571\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1059 - accuracy: 0.9675\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0853 - accuracy: 0.9734\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0748 - accuracy: 0.9767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 09:02:15.367874: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "# 3. 正規化されたデータセットをロードして学習\n",
    "# データセットをダウンロードして保存するディレクトリを指定\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "load_dir = './preproc_dataset'\n",
    "save_dir = './saved_model'\n",
    "\n",
    "# ディレクトリが存在しない場合にディレクトリを作成\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "with np.load(os.path.join(load_dir, 'mnist_normalized.npz'), allow_pickle=True) as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']\n",
    "    \n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.save(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1gmTvYttzBQ"
   },
   "source": [
    "## 1-4. モデルのテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Dlu_X0_thoo8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 09:05:26.003948: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-19 09:05:26.004014: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-02-19 09:05:29.914114: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-02-19 09:05:29.914182: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-02-19 09:05:29.914239: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (note-03-0): /proc/driver/nvidia/version does not exist\n",
      "2024-02-19 09:05:29.914588: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-19 09:05:31.379986: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2024-02-19 09:05:31.380759: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2111995000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 3s - loss: 0.0706 - accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07055041939020157, 0.977400004863739]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. モデルをロードしてテスト\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_load_dir = './preproc_dataset'\n",
    "model_load_dir = './saved_model'\n",
    "\n",
    "with np.load(os.path.join(data_load_dir, 'mnist_normalized.npz'), allow_pickle=True) as data:\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']\n",
    "\n",
    "model = tf.keras.models.load_model(model_load_dir)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uurTNSoLo--N"
   },
   "source": [
    "# 2. 推論実行（画像の数値を判別）\n",
    "\n",
    "トレーニングで利用したデータなので、まず正解するはず。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDZtKdolzMFZ"
   },
   "source": [
    "## 2-1. MNISTのデータを画像ファイル（PNG）としての保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8fIU1QGcpCYa"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "dir_path = 'data/images'\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 保存先のディレクトリを作成\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# 画像の保存\n",
    "for i in range(10):\n",
    "    img = Image.fromarray(x_train[i])\n",
    "    img.save(f'data/images/test_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gs8W44q2pRGC",
    "outputId": "fb8f0180-9678-444c-dc1c-bd27a6b1f270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_0.png\n",
      "test_1.png\n",
      "test_2.png\n",
      "test_3.png\n",
      "test_4.png\n",
      "test_5.png\n",
      "test_6.png\n",
      "test_7.png\n",
      "test_8.png\n",
      "test_9.png\n"
     ]
    }
   ],
   "source": [
    "!ls data/images/ | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYIx02_Jpn_p"
   },
   "source": [
    "画像の表示\n",
    "\n",
    "ファイルを指定する。（例： train_1.png）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tjuWaCKpviLm"
   },
   "outputs": [],
   "source": [
    "img_file_name = 'data/images/test_7.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZRhNN4Pvty9"
   },
   "source": [
    "指定した画像を表示して確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "0C2H6hu7pnKU",
    "outputId": "86402eaa-40a5-49a6-8ea9-d92500ad06b4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open(img_file_name)\n",
    "plt.imshow(img, cmap='gray')  # 画像がグレースケールなので cmap='gray' を指定\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3GNPHWbqJsC"
   },
   "source": [
    "## 2-2. 推論の実行\n",
    "\n",
    "事前に、img_file_name = 'data/images/test_7.png' を指定してあるはず。\n",
    "\n",
    "PIL（Python Image Library）のパッケージはPillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cgmU2bzDphr7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [3]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# モデルを保存してあるパス\n",
    "model_dir_path = './saved_model'\n",
    "\n",
    "# 画像の読み込み\n",
    "img = Image.open(img_file_name)\n",
    "\n",
    "# 画像をグレースケールに変換し、サイズを28x28にリサイズ\n",
    "img = img.convert('L').resize((28, 28))\n",
    "\n",
    "# NumPy配列に変換し、値を0から1の範囲に正規化\n",
    "img_array = np.array(img) / 255.0\n",
    "\n",
    "# モデルの入力形式に合わせるために配列の形状を変更（バッチサイズの次元を追加）\n",
    "img_array = img_array.reshape(1, 28, 28)\n",
    "\n",
    "# モデルのロード\n",
    "model = tf.keras.models.load_model(model_dir_path)  # モデルのパスを適切に設定\n",
    "\n",
    "# 推論\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbx1wmGnv-eT"
   },
   "source": [
    "補足： PIL（Pillow）のパッケージ確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Va3VxkOMqb6b",
    "outputId": "8eab1132-84f4-4a0a-cfd8-bc7c81195cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pillow                   9.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -i pillow"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "h9ZizciZmgQn"
   ],
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
