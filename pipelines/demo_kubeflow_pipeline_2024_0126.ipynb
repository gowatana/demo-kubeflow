{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26a9ddd",
   "metadata": {
    "id": "-PqeusNlukFs"
   },
   "source": [
    "TensorFlowを利用したMNISTのトレーニングを、Kubeflow Pipelinesに実装してみる。\n",
    "\n",
    "https://gist.github.com/gowatana/1fc66e48db015732e3a88870af2ac67b\n",
    "\n",
    "実行環境\n",
    "* Kubeflow 1.6.1\n",
    "* Notebook: kubeflownotebookswg/jupyter-tensorflow-full:v1.6.0\n",
    "* NGC Image: nvcr.io/nvidia/tensorflow:23.03-tf2-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d539d",
   "metadata": {
    "id": "iENvRY83y6ET"
   },
   "source": [
    "# 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf2229b",
   "metadata": {
    "id": "xNLaPLuxzE28"
   },
   "source": [
    "## KubeflowでNotebookを作成する\n",
    "* tensorflow, kfp などは、Notebookのコンテナ イメージ（jupyter-tensorflow-full:v1.6.0）に含まれている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619319e",
   "metadata": {
    "id": "3eIquLEsuNNi"
   },
   "source": [
    "## PVCの準備\n",
    "PVCを作成してあることを確認する。\n",
    "PVCは、Kubeflow UIのVolumesメニューから作成しておく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ecb72a",
   "metadata": {
    "id": "4b57b81f-db63-4a81-85ec-7087969c603f"
   },
   "outputs": [],
   "source": [
    "!kubectl get pvc demo-vol-01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204b293f",
   "metadata": {
    "id": "i45RIdWfzca6"
   },
   "source": [
    "# パイプラインの作成（モデルの作成→トレーニング→保存）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e150195",
   "metadata": {
    "id": "T_5xwt7fuVdN"
   },
   "source": [
    "kfpで、パイプラインのYAMLを作成する。\n",
    "* これは、トレーニングとモデルの保存を実行するパイプライン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0c8337",
   "metadata": {
    "id": "2874ffe5-6140-4db3-92ed-e422d5eeed45"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kfp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkfp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkfp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dsl\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkfp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcomp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kfp'"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "import kfp.components as comp\n",
    "\n",
    "def train_and_save_model():\n",
    "    import tensorflow as tf\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "    model.evaluate(x_test, y_test)\n",
    "\n",
    "    model.save('/mnt/demo-vol-01/mnist_saved_model')\n",
    "\n",
    "train_and_save_op = comp.func_to_container_op(train_and_save_model, base_image='tensorflow/tensorflow:latest')\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='Mnist Training Pipeline',\n",
    "    description='A pipeline that trains an MNIST model and saves it to PVC.'\n",
    ")\n",
    "\n",
    "def mnist_pipeline():\n",
    "    train_and_save_task = train_and_save_op()\n",
    "    train_and_save_task.add_pvolumes({'/mnt/demo-vol-01': dsl.PipelineVolume(pvc=\"demo-vol-01\")})\n",
    "\n",
    "kfp.compiler.Compiler().compile(mnist_pipeline, 'mnist_pipeline.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e01a4c",
   "metadata": {
    "id": "Rx6NKUTDu7-_"
   },
   "source": [
    "コンパイルで生成されたYAMLを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8cfcae",
   "metadata": {
    "id": "Lj64SxSOvCtP"
   },
   "outputs": [],
   "source": [
    "!cat mnist_pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c03da57",
   "metadata": {
    "id": "2LDWpQ3pvG-j"
   },
   "source": [
    "生成されたYAMLはローカルにダウンロードして、Kubeflow UIの「Pipelines (KFP)」からアップロードする。\n",
    "* ブラウザで、Kubeflow UI を開く\n",
    "* Pipelines 画面を開く\n",
    "* 「Upload Pipeline」からアップロードする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c51f898",
   "metadata": {
    "id": "b4GCERacvurF"
   },
   "source": [
    "パイプラインは、Argo Workflow（workflowリソース）として作成される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa97d96",
   "metadata": {
    "id": "7201c00e-9010-4b62-9886-553709644388"
   },
   "outputs": [],
   "source": [
    "!kubectl get workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4257427",
   "metadata": {
    "id": "xHUagtWUwPPM"
   },
   "source": [
    "# パイプラインの作成（テスト データでの推論を追加）\n",
    "kfpで、パイプラインのYAMLを作成する。\n",
    "* トレーニングとモデルの保存（train_and_save_op） → 推論（predict_op）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67099e46",
   "metadata": {
    "id": "35f72e46-4a8f-465f-8745-1121eb139cd9"
   },
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "import kfp.components as comp\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# トレーニング関数は以前のまま\n",
    "def train_and_save_model():\n",
    "    import tensorflow as tf\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "    model.evaluate(x_test, y_test)\n",
    "\n",
    "    model.save('/mnt/demo-vol-01/mnist_saved_model')\n",
    "\n",
    "# 推論を行う関数を定義\n",
    "def predict_model():\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    model = tf.keras.models.load_model('/mnt/demo-vol-01/mnist_saved_model')\n",
    "    new_data = np.random.rand(28, 28)\n",
    "    new_data = new_data.reshape(1, 28, 28) / 255.0\n",
    "    predictions = model.predict(new_data)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    print(\"Predicted class:\", predicted_class)\n",
    "    with open('/mnt/demo-vol-01/predictions.txt', 'w') as f:\n",
    "        f.write(\"Predicted class: \" + str(predicted_class[0]) + \"\\n\")\n",
    "\n",
    "# コンテナオペレーションを作成\n",
    "train_and_save_op = comp.func_to_container_op(train_and_save_model, base_image='tensorflow/tensorflow:latest')\n",
    "predict_op = comp.func_to_container_op(predict_model, base_image='tensorflow/tensorflow:latest')\n",
    "\n",
    "# パイプラインに推論タスクを追加\n",
    "@dsl.pipeline(\n",
    "    name='Mnist Training and Prediction Pipeline',\n",
    "    description='A pipeline that trains an MNIST model, saves it to PVC and makes a prediction.'\n",
    ")\n",
    "\n",
    "def mnist_pipeline():\n",
    "    # トレーニングタスク\n",
    "    train_and_save_task = train_and_save_op()\n",
    "    train_and_save_task.add_pvolumes({'/mnt/demo-vol-01': dsl.PipelineVolume(pvc=\"demo-vol-01\")})\n",
    "\n",
    "    # 推論タスク\n",
    "    predict_task = predict_op()\n",
    "    predict_task.add_pvolumes({'/mnt/demo-vol-01': dsl.PipelineVolume(pvc=\"demo-vol-01\")})\n",
    "\n",
    "    predict_task.after(train_and_save_task)\n",
    "\n",
    "# コンパイル\n",
    "kfp.compiler.Compiler().compile(mnist_pipeline, 'mnist_pipeline_and_predict.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea04172",
   "metadata": {
    "id": "JbrQFtoIw1Q5"
   },
   "source": [
    "コンパイルで生成されたYAMLを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0139222",
   "metadata": {
    "id": "6JpC_jZhw5vR"
   },
   "outputs": [],
   "source": [
    "!cat mnist_pipeline_and_predict.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c444c151",
   "metadata": {
    "id": "pZRa5eqxw79V"
   },
   "source": [
    "YAMLをアップロードする。\n",
    "\n",
    "生成されたYAMLはローカルにダウンロードして、Kubeflow UIの「Pipelines (KFP)」からアップロードする。\n",
    "* ブラウザで、Kubeflow UI を開く\n",
    "* Pipelines 画面を開く\n",
    "* 以前にアップロードしたパイプラインを開く\n",
    "* 「Upload version」からアップロードする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f27c6",
   "metadata": {
    "id": "oDv0gsp9yc7X"
   },
   "source": [
    "# Pipelineの実行\n",
    "\n",
    "パイプラインを実行する。\n",
    "* Experimentsの作成（ex-01）\n",
    "* 「Create Run」で、パイプラインを実行する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ba5389",
   "metadata": {
    "id": "L-qCpzvik4c9"
   },
   "source": [
    "# パイプラインの作成（コンテナ）\n",
    "\n",
    "トレーニングと推論のコードを、それぞれNGCのTensorFlowイメージでコンテナ化して利用する。\n",
    "\n",
    "* コンテナは ACR に配置ずみ。（ServiceAccount default-editorに、ImagePullSecretが必要）\n",
    "* PVC demo-vol-01 が必要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0444be1",
   "metadata": {
    "id": "Mxihm_4DlWh1"
   },
   "source": [
    "パイプラインをコンパイルするためのコード\n",
    "\n",
    "トレーニングと推論のコードは、コンテナ化して利用する。この定義は、下記のYAMLファイルとして分離されている。\n",
    "* train_and_save_model.yaml\n",
    "* predict_model.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e59862",
   "metadata": {
    "id": "eXd_xCi5l8LI"
   },
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "import kfp.components as comp\n",
    "\n",
    "# コンポーネントをファイルからロード\n",
    "train_and_save_op = kfp.components.load_component_from_file('train_and_save_model.yaml')\n",
    "predict_op = kfp.components.load_component_from_file('predict_model.yaml')\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='MNIST Training and Prediction Pipeline',\n",
    "    description='A pipeline that trains an MNIST model, saves it to PVC and makes a prediction.'\n",
    ")\n",
    "\n",
    "def mnist_pipeline():\n",
    "    # トレーニングタスク\n",
    "    train_and_save_task = train_and_save_op()\n",
    "    train_and_save_task.add_pvolumes({'/mnt/demo-vol-01': dsl.PipelineVolume(pvc=\"demo-vol-01\")})\n",
    "\n",
    "    # 推論タスク\n",
    "    predict_task = predict_op()\n",
    "    predict_task.add_pvolumes({'/mnt/demo-vol-01': dsl.PipelineVolume(pvc=\"demo-vol-01\")})\n",
    "    predict_task.after(train_and_save_task)\n",
    "\n",
    "# コンパイル\n",
    "kfp.compiler.Compiler().compile(mnist_pipeline, 'mnist_pipeline_and_predict_ctr.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11decc48",
   "metadata": {
    "id": "e8GWzEvhmiDw"
   },
   "source": [
    "YAMLが生成されたことを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36001fa",
   "metadata": {
    "id": "Ra3dp460mlJe"
   },
   "outputs": [],
   "source": [
    "!ls -l mnist_pipeline_and_predict_ctr.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319cfd7b",
   "metadata": {
    "id": "pk2p13wympBo"
   },
   "source": [
    "YAMLファイルは、Kubeflow PipelinesのUIからアップロードする。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hdTrbCscxYgU"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
