{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "-PqeusNlukFs",
      "metadata": {
        "id": "-PqeusNlukFs"
      },
      "source": [
        "TensorFlowを利用したMNISTのトレーニングを、Kubeflow Pipelinesに実装してみる。\n",
        "\n",
        "https://github.com/gowatana/demo-kubeflow/blob/main/tutorials/demo-tensorflow-mnist.ipynb\n",
        "\n",
        "実行環境\n",
        "* Kubeflow 1.6.1\n",
        "* Notebook: kubeflownotebookswg/jupyter-tensorflow-full:v1.6.0\n",
        "* NGC Image: nvcr.io/nvidia/tensorflow:23.03-tf2-py3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iENvRY83y6ET",
      "metadata": {
        "id": "iENvRY83y6ET"
      },
      "source": [
        "# 事前準備"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xNLaPLuxzE28",
      "metadata": {
        "id": "xNLaPLuxzE28"
      },
      "source": [
        "## KubeflowでNotebookを作成する\n",
        "* tensorflow, kfp などは、Notebookのコンテナ イメージ（jupyter-tensorflow-full:v1.6.0）に含まれている。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3eIquLEsuNNi",
      "metadata": {
        "id": "3eIquLEsuNNi"
      },
      "source": [
        "## PVCの準備\n",
        "PVCを作成してあることを確認する。\n",
        "PVCは、Kubeflow UIのVolumesメニューから作成しておく。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b57b81f-db63-4a81-85ec-7087969c603f",
      "metadata": {
        "id": "4b57b81f-db63-4a81-85ec-7087969c603f"
      },
      "outputs": [],
      "source": [
        "!kubectl get pvc demo-vol-01"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i45RIdWfzca6",
      "metadata": {
        "id": "i45RIdWfzca6"
      },
      "source": [
        "# パイプラインの作成（モデルの作成→トレーニング→保存）"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T_5xwt7fuVdN",
      "metadata": {
        "id": "T_5xwt7fuVdN"
      },
      "source": [
        "kfpで、パイプラインのYAMLを作成する。\n",
        "* これは、トレーニングとモデルの保存を実行するパイプライン"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2874ffe5-6140-4db3-92ed-e422d5eeed45",
      "metadata": {
        "id": "2874ffe5-6140-4db3-92ed-e422d5eeed45"
      },
      "outputs": [],
      "source": [
        "import kfp\n",
        "from kfp import dsl\n",
        "import kfp.components as comp\n",
        "\n",
        "def train_and_save_model():\n",
        "    import tensorflow as tf\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, epochs=5)\n",
        "    model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "    model.save('/mnt/demo-vol-01/mnist_saved_model')\n",
        "\n",
        "train_and_save_op = comp.func_to_container_op(train_and_save_model, base_image='tensorflow/tensorflow:latest')\n",
        "\n",
        "@dsl.pipeline(\n",
        "    name='Mnist Training Pipeline',\n",
        "    description='A pipeline that trains an MNIST model and saves it to PVC.'\n",
        ")\n",
        "\n",
        "def mnist_pipeline():\n",
        "    train_and_save_task = train_and_save_op()\n",
        "    train_and_save_task.add_pvolumes({'/mnt/demo-vol-01': dsl.PipelineVolume(pvc=\"demo-vol-01\")})\n",
        "\n",
        "kfp.compiler.Compiler().compile(mnist_pipeline, 'mnist_pipeline.yaml')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Rx6NKUTDu7-_",
      "metadata": {
        "id": "Rx6NKUTDu7-_"
      },
      "source": [
        "コンパイルで生成されたYAMLを確認する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Lj64SxSOvCtP",
      "metadata": {
        "id": "Lj64SxSOvCtP"
      },
      "outputs": [],
      "source": [
        "!cat mnist_pipeline.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2LDWpQ3pvG-j",
      "metadata": {
        "id": "2LDWpQ3pvG-j"
      },
      "source": [
        "生成されたYAMLはローカルにダウンロードして、Kubeflow UIの「Pipelines (KFP)」からアップロードする。\n",
        "* ブラウザで、Kubeflow UI を開く\n",
        "* Pipelines 画面を開く\n",
        "* 「Upload Pipeline」からアップロードする"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4GCERacvurF",
      "metadata": {
        "id": "b4GCERacvurF"
      },
      "source": [
        "パイプラインは、Argo Workflow（workflowリソース）として作成される。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7201c00e-9010-4b62-9886-553709644388",
      "metadata": {
        "id": "7201c00e-9010-4b62-9886-553709644388"
      },
      "outputs": [],
      "source": [
        "!kubectl get workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xHUagtWUwPPM",
      "metadata": {
        "id": "xHUagtWUwPPM"
      },
      "source": [
        "# パイプラインの作成（テスト データでの推論を追加）\n",
        "kfpで、パイプラインのYAMLを作成する。\n",
        "* トレーニングとモデルの保存（train_and_save_op） → 推論（predict_op）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35f72e46-4a8f-465f-8745-1121eb139cd9",
      "metadata": {
        "id": "35f72e46-4a8f-465f-8745-1121eb139cd9"
      },
      "outputs": [],
      "source": [
        "import kfp\n",
        "from kfp import dsl\n",
        "import kfp.components as comp\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# トレーニング関数は以前のまま\n",
        "def train_and_save_model():\n",
        "    import tensorflow as tf\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, epochs=5)\n",
        "    model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "    model.save('/mnt/demo-vol-01/mnist_saved_model')\n",
        "\n",
        "# 推論を行う関数を定義\n",
        "def predict_model():\n",
        "    import tensorflow as tf\n",
        "    import numpy as np\n",
        "    model = tf.keras.models.load_model('/mnt/demo-vol-01/mnist_saved_model')\n",
        "    new_data = np.random.rand(28, 28)\n",
        "    new_data = new_data.reshape(1, 28, 28) / 255.0\n",
        "    predictions = model.predict(new_data)\n",
        "    predicted_class = np.argmax(predictions, axis=1)\n",
        "    print(\"Predicted class:\", predicted_class)\n",
        "    with open('/mnt/demo-vol-01/predictions.txt', 'w') as f:\n",
        "        f.write(\"Predicted class: \" + str(predicted_class[0]) + \"\\n\")\n",
        "\n",
        "# コンテナオペレーションを作成\n",
        "train_and_save_op = comp.func_to_container_op(train_and_save_model, base_image='tensorflow/tensorflow:latest')\n",
        "predict_op = comp.func_to_container_op(predict_model, base_image='tensorflow/tensorflow:latest')\n",
        "\n",
        "# パイプラインに推論タスクを追加\n",
        "@dsl.pipeline(\n",
        "    name='Mnist Training and Prediction Pipeline',\n",
        "    description='A pipeline that trains an MNIST model, saves it to PVC and makes a prediction.'\n",
        ")\n",
        "\n",
        "def mnist_pipeline():\n",
        "    # トレーニングタスク\n",
        "    train_and_save_task = train_and_save_op()\n",
        "    train_and_save_task.add_pvolumes({'/mnt/demo-vol-01': dsl.PipelineVolume(pvc=\"demo-vol-01\")})\n",
        "\n",
        "    # 推論タスク\n",
        "    predict_task = predict_op()\n",
        "    predict_task.add_pvolumes({'/mnt/demo-vol-01': dsl.PipelineVolume(pvc=\"demo-vol-01\")})\n",
        "\n",
        "    predict_task.after(train_and_save_task)\n",
        "\n",
        "# コンパイル\n",
        "kfp.compiler.Compiler().compile(mnist_pipeline, 'mnist_pipeline_and_predict.yaml')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JbrQFtoIw1Q5",
      "metadata": {
        "id": "JbrQFtoIw1Q5"
      },
      "source": [
        "コンパイルで生成されたYAMLを確認する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6JpC_jZhw5vR",
      "metadata": {
        "id": "6JpC_jZhw5vR"
      },
      "outputs": [],
      "source": [
        "!cat mnist_pipeline_and_predict.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pZRa5eqxw79V",
      "metadata": {
        "id": "pZRa5eqxw79V"
      },
      "source": [
        "YAMLをアップロードする。\n",
        "\n",
        "生成されたYAMLはローカルにダウンロードして、Kubeflow UIの「Pipelines (KFP)」からアップロードする。\n",
        "* ブラウザで、Kubeflow UI を開く\n",
        "* Pipelines 画面を開く\n",
        "* 以前にアップロードしたパイプラインを開く\n",
        "* 「Upload version」からアップロードする"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oDv0gsp9yc7X",
      "metadata": {
        "id": "oDv0gsp9yc7X"
      },
      "source": [
        "# パイプラインの実行\n",
        "\n",
        "パイプラインを実行する。\n",
        "* Experimentsの作成（ex-01）\n",
        "* 「Create Run」で、パイプラインを実行する。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L-qCpzvik4c9",
      "metadata": {
        "id": "L-qCpzvik4c9"
      },
      "source": [
        "# パイプラインの作成（コンテナ）\n",
        "\n",
        "トレーニングと推論のコードを、それぞれNGCのTensorFlowイメージでコンテナ化して利用する。\n",
        "\n",
        "* コンテナは ACR に配置ずみ。（ServiceAccount default-editorに、ImagePullSecretが必要）\n",
        "* PVC demo-vol-01 が必要"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mxihm_4DlWh1",
      "metadata": {
        "id": "Mxihm_4DlWh1"
      },
      "source": [
        "パイプラインをコンパイルするためのコード\n",
        "\n",
        "トレーニングと推論のコードは、コンテナ化して利用する。この定義は、下記のYAMLファイルとして分離されている。\n",
        "* train_and_save_model.yaml\n",
        "* predict_model.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eXd_xCi5l8LI",
      "metadata": {
        "id": "eXd_xCi5l8LI"
      },
      "outputs": [],
      "source": [
        "import kfp\n",
        "from kfp import dsl\n",
        "import kfp.components as comp\n",
        "\n",
        "# コンポーネントをファイルからロード\n",
        "train_and_save_op = kfp.components.load_component_from_file('train_and_save_model.yaml')\n",
        "predict_op = kfp.components.load_component_from_file('predict_model.yaml')\n",
        "\n",
        "@dsl.pipeline(\n",
        "    name='MNIST Training and Prediction Pipeline',\n",
        "    description='A pipeline that trains an MNIST model, saves it to PVC and makes a prediction.'\n",
        ")\n",
        "\n",
        "def mnist_pipeline():\n",
        "    # トレーニングタスク\n",
        "    train_and_save_task = train_and_save_op()\n",
        "    train_and_save_task.add_pvolumes({'/mnt/demo-vol-01': dsl.PipelineVolume(pvc=\"demo-vol-01\")})\n",
        "\n",
        "    # 推論タスク\n",
        "    predict_task = predict_op()\n",
        "    predict_task.add_pvolumes({'/mnt/demo-vol-01': dsl.PipelineVolume(pvc=\"demo-vol-01\")})\n",
        "    predict_task.after(train_and_save_task)\n",
        "\n",
        "# コンパイル\n",
        "kfp.compiler.Compiler().compile(mnist_pipeline, 'mnist_pipeline_and_predict_ctr.yaml')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8GWzEvhmiDw",
      "metadata": {
        "id": "e8GWzEvhmiDw"
      },
      "source": [
        "YAMLが生成されたことを確認する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ra3dp460mlJe",
      "metadata": {
        "id": "Ra3dp460mlJe"
      },
      "outputs": [],
      "source": [
        "!ls -l mnist_pipeline_and_predict_ctr.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pk2p13wympBo",
      "metadata": {
        "id": "pk2p13wympBo"
      },
      "source": [
        "YAMLファイルは、Kubeflow PipelinesのUIからアップロードする。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XEFjOutesjIY",
      "metadata": {
        "id": "XEFjOutesjIY"
      },
      "source": [
        "# PVに保存されたデータの確認\n",
        "\n",
        "PVをマウントしたPodを起動して、保存されたデータを確認する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YW1Zf7vMsyMo",
      "metadata": {
        "id": "YW1Zf7vMsyMo"
      },
      "outputs": [],
      "source": [
        "!kubectl apply -f pod.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uXKU4Qits4Au",
      "metadata": {
        "id": "uXKU4Qits4Au"
      },
      "outputs": [],
      "source": [
        "!kubectl get pod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ogoPaOJstTCv",
      "metadata": {
        "id": "ogoPaOJstTCv"
      },
      "outputs": [],
      "source": [
        "!kubectl exec demo-vol-01-pod  -- df /mnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h_XIJ_0ps-lA",
      "metadata": {
        "id": "h_XIJ_0ps-lA"
      },
      "outputs": [],
      "source": [
        "!kubectl exec demo-vol-01-pod -- ls /mnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27ZD01dhtbx8",
      "metadata": {
        "id": "27ZD01dhtbx8"
      },
      "outputs": [],
      "source": [
        "!kubectl exec demo-vol-01-pod  -- cat /mnt/predictions.txt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
